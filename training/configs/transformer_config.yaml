# Transformer Beam Prediction Configuration

model:
  name: "Transformer_Beam_Predictor"
  type: "transformer"
  
  architecture:
    input_dim: 12  # Channel measurements + position
    d_model: 128
    num_heads: 8
    num_layers: 4
    d_ff: 512
    num_antennas: 64  # Massive MIMO array size
    dropout: 0.1
    
  training:
    learning_rate: 0.0001
    weight_decay: 0.0001
    batch_size: 32
    sequence_length: 10
    max_epochs: 500
    scheduler_t0: 10
    
  beam:
    array_type: "uniform_planar"  # UPA or ULA
    frequency_ghz: 28  # mmWave/sub-THz
    spacing_wavelength: 0.5
    
  training_data:
    channel_model: "3gpp_38.901"
    scenario: "uma"  # Urban Macro
    mobility_model: "random_waypoint"
    num_users: 100
    
  evaluation:
    metrics: ["beam_alignment_error", "spectral_efficiency", "inference_time"]
    target_inference_ms: 1.0  # Sub-millisecond target
    eval_frequency: 25
    
  deployment:
    max_inference_time_ms: 1.0
    use_mixed_precision: true
    optimize_for_inference: true
    model_path: "models/transformer_beam_predictor.pth"
